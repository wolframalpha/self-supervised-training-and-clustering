{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import augdataset\n",
    "import loss, train_utils, models\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(filename='train_status.log',\n",
    "                            filemode='a',\n",
    "                            format='%(asctime)s %(message)s',\n",
    "                            datefmt='%H:%M:%S',\n",
    "                            level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images:  4356\n",
      "Compose(\n",
      "    Resize(size=(150, 150), interpolation=PIL.Image.BILINEAR)\n",
      "    RandomResizedCrop(size=(150, 150), scale=(0.2, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    RandomVerticalFlip(p=0.5)\n",
      "    RandomApply(\n",
      "    p=0.8\n",
      "    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])\n",
      ")\n",
      "    RandomGrayscale(p=0.2)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.201])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# get the trainig data\n",
    "train_dataloader = augdataset.get_train_dl(dirs=['/home/devi_prasad/UrineSedimentation/data_imgs/10k_annotatio_details_20200901/confusing/*.*'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model \n",
    "# output feature size = 128\n",
    "model = models.Model(features_dim=128)\n",
    "model = model.cuda()\n",
    "# resume training\n",
    "# model = torch.load('models/modelv1-Copy1.0.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in model.parameters():\n",
    "#     print(param.requires_grad)# = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 2\n",
    "# SimCLR loss https://arxiv.org/pdf/2002.05709.pdf\n",
    "criterion = loss.SimCLRLoss(temperature=0.1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# decay the learning rate by 0.1 after every 500 epochs\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 200, gamma=0.1, last_epoch=-1,)\n",
    "\n",
    "# decay by .1 if no improvement for 100 epochs\n",
    "scheduler = utils.ReduceLROnPlateauWithBacktrack(optimizer, model, filename=f'models/modelv{v}.pt', factor=0.1, verbose=False, patience=100, warmup_steps=0, eps=1e-8)\n",
    "n_epochs = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 total_loss 67.42889088392258 lr : 0.0016\n",
      "Epoch 1 total_loss 44.26941004395485 lr : 0.00175\n",
      "Epoch 2 total_loss 35.78485497832298 lr : 0.001\n",
      "Epoch 3 total_loss 31.17360121011734 lr : 0.001\n",
      "Epoch 4 total_loss 28.72191560268402 lr : 0.001\n",
      "Epoch 5 total_loss 27.110676765441895 lr : 0.001\n",
      "Epoch 6 total_loss 25.084012486040592 lr : 0.001\n",
      "Epoch 7 total_loss 24.755797296762466 lr : 0.001\n",
      "Epoch 8 total_loss 24.886099964380264 lr : 0.001\n",
      "Epoch 9 total_loss 23.581283420324326 lr : 0.001\n",
      "Epoch 10 total_loss 22.61112755537033 lr : 0.0013\n",
      "Epoch 11 total_loss 21.113924026489258 lr : 0.001\n",
      "Epoch 12 total_loss 21.580912321805954 lr : 0.001\n",
      "Epoch 13 total_loss 20.613198846578598 lr : 0.001\n",
      "Epoch 14 total_loss 20.189198911190033 lr : 0.001\n",
      "Epoch 15 total_loss 20.252035975456238 lr : 0.001\n",
      "Epoch 16 total_loss 19.524524301290512 lr : 0.001\n",
      "Epoch 17 total_loss 18.586153157055378 lr : 0.0016\n",
      "Epoch 18 total_loss 18.18667009472847 lr : 0.001\n",
      "Epoch 19 total_loss 17.95823523402214 lr : 0.0012\n",
      "Epoch 20 total_loss 18.301016256213188 lr : 0.001\n",
      "Epoch 21 total_loss 17.869991302490234 lr : 0.001\n",
      "Epoch 22 total_loss 19.8943203240633 lr : 0.0014\n",
      "Epoch 23 total_loss 18.259073957800865 lr : 0.001\n",
      "Epoch 24 total_loss 17.850003957748413 lr : 0.001\n",
      "Epoch 25 total_loss 22.132267743349075 lr : 0.001\n",
      "Epoch 26 total_loss 19.26628440618515 lr : 0.001\n",
      "Epoch 27 total_loss 17.933465152978897 lr : 0.001\n",
      "Epoch 28 total_loss 17.63374814391136 lr : 0.0016\n",
      "Epoch 29 total_loss 16.15009155869484 lr : 0.0014\n",
      "Epoch 30 total_loss 15.948167890310287 lr : 0.001\n",
      "Epoch 31 total_loss 15.622210010886192 lr : 0.001\n",
      "Epoch 32 total_loss 15.00188222527504 lr : 0.001\n",
      "Epoch 33 total_loss 15.958349168300629 lr : 0.001\n",
      "Epoch 34 total_loss 15.120028167963028 lr : 0.001\n",
      "Epoch 35 total_loss 15.025561556220055 lr : 0.001\n",
      "Epoch 36 total_loss 15.16406635940075 lr : 0.0013\n",
      "Epoch 37 total_loss 14.717950999736786 lr : 0.001\n",
      "Epoch 38 total_loss 16.14961126446724 lr : 0.001\n",
      "Epoch 39 total_loss 15.494489848613739 lr : 0.001\n",
      "Epoch 40 total_loss 14.8886137008667 lr : 0.0012\n",
      "Epoch 41 total_loss 15.3813616335392 lr : 0.0011\n",
      "Epoch 42 total_loss 14.024166941642761 lr : 0.001\n",
      "Epoch 43 total_loss 14.29086548089981 lr : 0.001\n",
      "Epoch 44 total_loss 19.282632023096085 lr : 0.001\n",
      "Epoch 45 total_loss 17.154915273189545 lr : 0.001\n",
      "Epoch 46 total_loss 17.913629829883575 lr : 0.001\n",
      "Epoch 47 total_loss 14.864943861961365 lr : 0.001\n",
      "Epoch 48 total_loss 14.31037813425064 lr : 0.001\n",
      "Epoch 49 total_loss 14.072866201400757 lr : 0.001\n",
      "Epoch 50 total_loss 13.3872991502285 lr : 0.00101\n",
      "Epoch 51 total_loss 13.244753018021584 lr : 0.001\n",
      "Epoch 52 total_loss 14.462851420044899 lr : 0.001\n",
      "Epoch 53 total_loss 13.307581081986427 lr : 0.001\n",
      "Epoch 54 total_loss 13.016241490840912 lr : 0.001\n",
      "Epoch 55 total_loss 13.125973843038082 lr : 0.001\n",
      "Epoch 56 total_loss 12.792444407939911 lr : 0.001\n",
      "Epoch 57 total_loss 12.80309146642685 lr : 0.001\n",
      "Epoch 58 total_loss 12.021277606487274 lr : 0.001\n",
      "minibatch: 2 running_loss: 0.8665810823440552\r"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    total_loss = train_utils.train(train_dataloader, model, criterion, optimizer)\n",
    "    \n",
    "    print(f\"Epoch {epoch} total_loss {total_loss} lr : {optimizer.param_groups[0]['lr']}\", )\n",
    "    \n",
    "    logging.info(f\"modelv{v} Epoch {epoch} total_loss {total_loss} lr {optimizer.param_groups[0]['lr']}\")\n",
    "    scheduler.step([-total_loss])\n",
    "    \n",
    "    torch.save([model, optimizer], f'models/modelv{v}_curr.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
